{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelight9713/NEWGAME/blob/main/0529)(%EA%B9%80%EB%8F%99%ED%98%84)%EB%AF%B8%EB%8B%88%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_resnet_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmHnjsnNcSj7",
        "outputId": "df7757ee-bbea-4948-ec6c-8448f6c166b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
      ],
      "metadata": {
        "id": "np60AWzzc6Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !unzip -qq '/content/drive/MyDrive/Colab Notebooks/data/re_g_img-20240529T105207Z-001.zip' # 동현 계정용\n",
        "!unzip -qq '/content/drive/MyDrive/datafile/re_g_img-20240529T105207Z-001.zip'  # 20200666 계정용"
      ],
      "metadata": {
        "id": "ecHps4O02TbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !unzip -qq '/content/drive/MyDrive/Colab Notebooks/data/re_g_img-20240529T105207Z-001.zip' # 동현 계정용\n",
        "!unzip -qq '/content/drive/MyDrive/datafile/re_g_img-20240529T105207Z-001.zip'  # 20200666 계정용"
      ],
      "metadata": {
        "id": "Et2Ow48BptLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 이름 목록 (예시)\n",
        "class_names = [\"퍼즐\" ,\"퀴즈\", \"캐주얼\" ,\"전략\" ,\"음악\", \"어드벤처\",\"액션\", \"아케이드\",  \"시뮬레이션\" ,\"스포츠\", \"보드\", \"롤플레잉\", \"레이싱\"]\n",
        "\n",
        "\n",
        "# 새로운 클래스 폴더를 생성할 디렉토리\n",
        "# class_dir_base = r'/content/drive/MyDrive/Colab Notebooks/data/test/test21/' # 본 계정용\n",
        "class_dir_base = r'/content/drive/MyDrive/Colab Notebooks/data/test' # 부계용\n",
        "# 클래스 폴더 생성\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(class_dir_base, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "doYQSLWCVkoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import AutoImageProcessor\n",
        "\n",
        "# 기존 이미지 파일이 있는 디렉토리\n",
        "# extract_dir = r'/content/re_g_img/'\n",
        "extract_dir = r'/content/re_g_img/' #부계용\n",
        "\n",
        "# 새로운 클래스 폴더를 생성할 디렉토리\n",
        "# class_dir_base = r'/content/drive/MyDrive/Colab Notebooks/data/test/test21/' # 본계\n",
        "class_dir_base = r'/content/drive/MyDrive/Colab Notebooks/data/test/' # 부계\n",
        "# # 클래스 폴더 생성 함수\n",
        "# def create_class_folders(base_dir, class_names):\n",
        "#     for class_name in class_names:\n",
        "#         class_dir = os.path.join(base_dir, class_name)\n",
        "#         os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 이미지 파일을 클래스 폴더로 이동시키기\n",
        "def organize_images_into_class_folders(src_dir, dest_dir):\n",
        "    # if not os.path.exists(dest_dir):\n",
        "    #     os.makedirs(dest_dir)\n",
        "    for foldername in os.listdir(src_dir): # 원본 파일이 들어있는 경로(안에 카테고리 폴더- 이미지 순으로배열ㄹ)\n",
        "        old_class_dir = os.path.join(src_dir, foldername)\n",
        "        class_dir = os.path.join(dest_dir, foldername)\n",
        "        # print(old_class_dir,'++', class_dir)\n",
        "#         # print(src_dir+foldername)\n",
        "        for filename in os.listdir(old_class_dir):\n",
        "          # print(src_dir+foldername+'/'+filename)\n",
        "#           # print(foldername)\n",
        "\n",
        "            src_file = os.path.join(old_class_dir, filename)\n",
        "            dest_file = os.path.join(class_dir, filename)\n",
        "            shutil.move(src_file, dest_file)\n",
        "\n",
        "\n",
        "\n",
        "    # for filename in os.listdir(src_dir):\n",
        "    #     print(src_dir+filename)\n",
        "\n",
        "    #     if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "    #         class_name = extract_class_from_filename(filename)\n",
        "    #         class_dir = os.path.join(dest_dir, class_name)\n",
        "    #         if not os.path.exists(class_dir):\n",
        "    #             os.makedirs(class_dir)\n",
        "    #         src_file = os.path.join(src_dir, filename)\n",
        "    #         dest_file = os.path.join(class_dir, filename)\n",
        "    #         shutil.move(src_file, dest_file)\n",
        "\n",
        "# 기존 폴더 구조를 클래스 폴더로 정리\n",
        "organize_images_into_class_folders(extract_dir, class_dir_base)\n",
        "\n",
        "# # 데이터 전처리기 설정\n",
        "# processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "# # 데이터셋 준비\n",
        "# dataset = datasets.ImageFolder(root=class_dir_base, transform=transform)"
      ],
      "metadata": {
        "id": "VNl9nMpvFG8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bO9K6cphkoyC",
        "outputId": "e5c7da98-e427-41f1-e3bf-6326f63adaaa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '아케이드'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-976fa3c8da9e>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# input_dir 내 모든 이미지 파일에 대해 증강 작업 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_inner_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_inner_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_inner_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '아케이드'"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "# 데이터 증강을 위한 ImageDataGenerator 객체 생성\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,        # 이미지 회전 범위 (degrees)\n",
        "    width_shift_range=0.2,    # 수평 이동 범위\n",
        "    height_shift_range=0.2,   # 수직 이동 범위\n",
        "    shear_range=0.2,          # 층밀리기 변환 범위\n",
        "    zoom_range=0.2,           # 확대 축소 범위\n",
        "    horizontal_flip=True,     # 수평 반전\n",
        "    fill_mode='nearest'       # 빈 공간을 채우는 방식\n",
        ")\n",
        "\n",
        "# !unzip -qq /content/drive/MyDrive/Colab Notebooks/data/어드벤처-20240529T095912Z-001.zip\n",
        "# 이미지가 저장된 디렉토리 경로와 출력 디렉토리 경로\n",
        "# input_dir = r\"/content/re_g_img/레이싱\"\n",
        "\n",
        "input_dir = r\"/content/re_g_img/\"\n",
        "# output_dir = r\"/content/drive/MyDrive/Colab Notebooks/data/test/test21\"\n",
        "output_dir = r\"/content/drive/MyDrive/Colab Notebooks/data/test/test21\"\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# 클래스 이름 목록 (예시)\n",
        "class_names = [\"퍼즐\" ,\"퀴즈\", \"캐주얼\" ,\"전략\" ,\"음악\", \"어드벤처\",\"액션\", \"아케이드\",  \"시뮬레이션\" ,\"스포츠\", \"보드\", \"롤플레잉\", \"레이싱\"]\n",
        "\n",
        "# 클래스 폴더 생성\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(extract_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "# # 예시: 이미지 파일을 클래스 폴더로 이동\n",
        "# # 이 부분은 데이터셋의 실제 구조에 따라 다릅니다.\n",
        "# for img_file in os.listdir(extract_dir):\n",
        "#     if img_file.endswith('.jpg'):\n",
        "#         class_name = determine_class_from_filename(img_file)  # 파일명에서 클래스 이름을 추출하는 함수\n",
        "#         shutil.move(os.path.join(extract_dir, img_file), os.path.join(extract_dir, class_name, img_file))\n",
        "#=================\n",
        "\n",
        "\n",
        "# 출력 디렉토리가 존재하지 않으면 생성\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# 증강할 이미지 개수\n",
        "num_augmented_images = 3\n",
        "\n",
        "# input_dir 내 모든 이미지 파일에 대해 증강 작업 수행\n",
        "for input_inner_dir in os.listdir(input_dir):\n",
        "    for img_name in os.listdir(input_inner_dir):\n",
        "        img_path = os.path.join(input_inner_dir, img_name)\n",
        "\n",
        "        try:\n",
        "            img = load_img(img_path)  # PIL 이미지\n",
        "        except:\n",
        "            print(f\"Error loading image {img_path}\")\n",
        "            continue\n",
        "\n",
        "        x = img_to_array(img)  # (height, width, channels)로 변환된 Numpy 배열\n",
        "        x = np.expand_dims(x, axis=0)  # (1, height, width, channels)로 변환\n",
        "\n",
        "        # 이미지 증강 및 저장\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_dir, save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i >= num_augmented_images:\n",
        "                break  # 원하는 수만큼 증강된 이미지를 생성한 후 종료\n",
        "\n",
        "    print(f\"{num_augmented_images}개의 증강된 이미지를 {output_dir}에 저장했습니다.\")\n",
        "##  input_dir 내 모든 이미지 파일에 대해 증강 작업 수행\n",
        "# for img_name in os.listdir(input_dir):\n",
        "#     img_path = os.path.join(input_dir, img_name)\n",
        "\n",
        "#     try:\n",
        "#         img = load_img(img_path)  # PIL 이미지\n",
        "#     except:\n",
        "#         print(f\"Error loading image {img_path}\")\n",
        "#         continue\n",
        "\n",
        "#     x = img_to_array(img)  # (height, width, channels)로 변환된 Numpy 배열\n",
        "#     x = np.expand_dims(x, axis=0)  # (1, height, width, channels)로 변환\n",
        "\n",
        "#     # 이미지 증강 및 저장\n",
        "#     i = 0\n",
        "#     for batch in datagen.flow(x, batch_size=1, save_to_dir=output_dir, save_prefix='aug', save_format='jpg'):\n",
        "#         i += 1\n",
        "#         if i >= num_augmented_images:\n",
        "#             break  # 원하는 수만큼 증강된 이미지를 생성한 후 종료\n",
        "\n",
        "# print(f\"{num_augmented_images}개의 증강된 이미지를 {output_dir}에 저장했습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.ㅇㅇㅇㅇ"
      ],
      "metadata": {
        "id": "XglZMP8QkvKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "# # 압축 파일 경로\n",
        "# zip_file_path = '/content/drive/MyDrive/Colab Notebooks/data/데이터프레임-20240529T085655Z-001.zip'\n",
        "# extract_dir = r'/content/drive/MyDrive/Colab Notebooks/data/test' # 본계\n",
        "extract_dir = r'/content/drive/MyDrive/Colab Notebooks/data/test' # 부계\n",
        "# # 압축 파일 해제\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_dir)\n",
        "\n",
        "# 데이터 전처리기 설정\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "print(f\"레즈넷 데이터 전처리기 설정 완료\")\n",
        "\n",
        "# # 데이터셋 준비\n",
        "# dataset = datasets.ImageFolder(root=extract_dir, transform=transform) 원래 받은 것\n",
        "dataset = datasets.ImageFolder(root=extract_dir, transform=transform)\n",
        "label_encoder = LabelEncoder()\n",
        "dataset.targets = label_encoder.fit_transform(dataset.targets)\n",
        "print(\"레즈넷 데이터셋 설정 완료\")\n",
        "\n",
        "# 학습/검증 데이터셋 분리\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "# 모델 로드\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\", num_labels=len(label_encoder.classes_))\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "# 모델 학습\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        inputs = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(pixel_values=inputs)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataloader)}\")\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_dataloader:\n",
        "        inputs = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "        outputs = model(pixel_values=inputs)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total}%')\n",
        "\n",
        "# 예측 예시\n",
        "example_image_path = '/content/어드벤처/어드벤처!Roblox(2).jpg'\n",
        "example_image = Image.open(example_image_path)\n",
        "example_image = transform(example_image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(pixel_values=example_image).logits\n",
        "\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "predicted_category = label_encoder.inverse_transform([predicted_label])[0]\n",
        "print(f\"Predicted category: {predicted_category}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "4LYgEqsakvst",
        "outputId": "81029a95-447d-4c21-899f-2615f3d58e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ResNetForImageClassification:\n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([1000, 2048]) from checkpoint, the shape in current model is torch.Size([1, 2048]).\n\tsize mismatch for classifier.1.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ad9feac14be3>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNetForImageClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"microsoft/resnet-50\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# 손실 함수 및 옵티마이저 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3752\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3753\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3754\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3755\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3756\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4263\u001b[0m                     \u001b[0;34m\"\\n\\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4264\u001b[0m                 )\n\u001b[0;32m-> 4265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNetForImageClassification:\n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([1000, 2048]) from checkpoint, the shape in current model is torch.Size([1, 2048]).\n\tsize mismatch for classifier.1.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.44ㅇㅇ"
      ],
      "metadata": {
        "id": "y2086yruGfV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import AutoImageProcessor\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 기존 이미지 파일이 있는 디렉토리\n",
        "extract_dir = r'/content/re_g_img/'\n",
        "\n",
        "# 새로운 클래스 폴더를 생성할 디렉토리\n",
        "class_dir_base = r'/content/drive/MyDrive/Colab Notebooks/data/test/test21'\n",
        "\n",
        "# # 클래스 이름을 추출하는 함수 (예시)\n",
        "# def extract_class_from_filename(filename):\n",
        "#     return filename.split('!')[0]  # 예: 'class1_img1.jpg' -> 'class1'\n",
        "\n",
        "# 클래스 이름 목록 (예시)\n",
        "class_names = [\"퍼즐\" ,\"퀴즈\", \"캐주얼\" ,\"전략\" ,\"음악\", \"어드벤처\",\"액션\", \"아케이드\",  \"시뮬레이션\" ,\"스포츠\", \"보드\", \"롤플레잉\", \"레이싱\"]\n",
        "\n",
        "# 클래스 폴더 생성\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(extract_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# 이미지 파일을 클래스 폴더로 이동시키기\n",
        "def organize_images_into_class_folders(src_dir, dest_dir):\n",
        "    # if not os.path.exists(dest_dir):\n",
        "    #     os.makedirs(dest_dir)\n",
        "\n",
        "    for filename in os.listdir(src_dir):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            class_name = extract_class_from_filename(filename)\n",
        "            class_dir = os.path.join(dest_dir, class_name)\n",
        "            if not os.path.exists(class_dir):\n",
        "                os.makedirs(class_dir)\n",
        "            src_file = os.path.join(src_dir, filename)\n",
        "            dest_file = os.path.join(class_dir, filename)\n",
        "            shutil.move(src_file, dest_file)\n",
        "\n",
        "# 기존 폴더 구조를 클래스 폴더로 정리\n",
        "organize_images_into_class_folders(class_dir, class_dir_base)\n",
        "\n",
        "# 데이터 전처리기 설정\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# 데이터셋 준비\n",
        "dataset = datasets.ImageFolder(root=class_dir_base, transform=transform)\n",
        "\n",
        "# 데이터로더 설정\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 모델 준비\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "# 모델을 GPU로 이동 (가능한 경우)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 학습 루프 (간단한 예제)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in tqdm(dataloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsYpwss4GcI2",
        "outputId": "a8dbe738-9a89-4e07-b1f1-34042ccd40aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:04<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 8.388590812683105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Loss: 7.564304828643799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Loss: 7.407388210296631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Loss: 7.102797985076904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Loss: 7.566795349121094\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_dataloader:\n",
        "        inputs = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "        outputs = model(pixel_values=inputs)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total}%')\n",
        "\n",
        "# 예측 예시\n",
        "example_image_path = '/content/어드벤처/어드벤처!Roblox(2).jpg'\n",
        "example_image = Image.open(example_image_path)\n",
        "example_image = transform(example_image).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(pixel_values=example_image).logits\n",
        "\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "predicted_category = label_encoder.inverse_transform([predicted_label])[0]\n",
        "print(f\"Predicted category: {predicted_category}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "HiE-B_OyMcHv",
        "outputId": "9de5c1e6-4d31-4c11-90e4-c14526df4f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.0%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: [917]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d6f84f1f4941>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpredicted_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted category: {predicted_category}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y contains previously unseen labels: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [917]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "# 데이터 증강을 위한 ImageDataGenerator 객체 생성\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,        # 이미지 회전 범위 (degrees)\n",
        "    width_shift_range=0.2,    # 수평 이동 범위\n",
        "    height_shift_range=0.2,   # 수직 이동 범위\n",
        "    shear_range=0.2,          # 층밀리기 변환 범위\n",
        "    zoom_range=0.2,           # 확대 축소 범위\n",
        "    horizontal_flip=True,     # 수평 반전\n",
        "    fill_mode='nearest'       # 빈 공간을 채우는 방식\n",
        ")\n",
        "\n",
        "# 이미지가 저장된 디렉토리 경로와 출력 디렉토리 경로\n",
        "input_dir = '/content/Test'\n",
        "output_dir = '/content/Test img'\n",
        "\n",
        "# 출력 디렉토리가 존재하지 않으면 생성\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# 증강할 이미지 개수\n",
        "num_augmented_images = 3\n",
        "\n",
        "# input_dir 내 모든 이미지 파일에 대해 증강 작업 수행\n",
        "for img_name in os.listdir(input_dir):\n",
        "    img_path = os.path.join(input_dir, img_name)\n",
        "\n",
        "    try:\n",
        "        img = load_img(img_path)  # PIL 이미지\n",
        "    except:\n",
        "        print(f\"Error loading image {img_path}\")\n",
        "        continue\n",
        "\n",
        "    x = img_to_array(img)  # (height, width, channels)로 변환된 Numpy 배열\n",
        "    x = np.expand_dims(x, axis=0)  # (1, height, width, channels)로 변환\n",
        "\n",
        "    # 이미지 증강 및 저장\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=1, save_to_dir=output_dir, save_prefix='aug', save_format='jpg'):\n",
        "        i += 1\n",
        "        if i >= num_augmented_images:\n",
        "            break  # 원하는 수만큼 증강된 이미지를 생성한 후 종료\n",
        "\n",
        "print(f\"{num_augmented_images}개의 증강된 이미지를 {output_dir}에 저장했습니다.\")"
      ],
      "metadata": {
        "id": "_8a7T9BJSXq0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}